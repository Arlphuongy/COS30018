import os
import time
import dotenv
import gradio as gr
import google.generativeai as genai

#load environment variables
dotenv.load_dotenv(".env.local")

#initialize gemini api
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
genai.configure(api_key=GEMINI_API_KEY)

#set the model to use - we know gemini-1.5-flash works
MODEL_NAME = "models/gemini-1.5-flash"
print(f"Using model: {MODEL_NAME}")

#import the retrieval module
from retrieval import search_legal_documents


#format the retrieved documents into a readable string for the llm
def format_documents(results):
    if not results:
        return "No documents found."
    
    formatted_docs = ""
    for i, result in enumerate(results):
        metadata = result.payload.get('metadata', {})
        text = result.payload.get('text', '')
        thong_tu = metadata.get('Th√¥ng t∆∞', 'Unknown')
        dieu = metadata.get('ƒêi·ªÅu', 'Unknown')
        score = result.score  # Get the relevance score
        
        formatted_docs += f"T√†i li·ªáu #{i+1} (ƒê·ªô tin c·∫≠y: {score:.4f}):\n"
        formatted_docs += f"Ngu·ªìn: Th√¥ng t∆∞ {thong_tu}, ƒêi·ªÅu {dieu}\n"
        formatted_docs += f"N·ªôi dung: {text}\n\n"
    
    return formatted_docs

#create full prompt for the model
def create_prompt(query, documents):
    system_instructions = """
    B·∫°n l√† tr·ª£ l√Ω ph√°p l√Ω chuy√™n v·ªÅ lu·∫≠t ph√°p Vi·ªát Nam. Nhi·ªám v·ª• c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi d√πng hi·ªÉu r√µ c√°c quy ƒë·ªãnh ph√°p lu·∫≠t 
    d·ª±a tr√™n c√°c t√†i li·ªáu ph√°p l√Ω ƒë∆∞·ª£c cung c·∫•p. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n th√¥ng tin trong c√°c t√†i li·ªáu.
    
    Nguy√™n t·∫Øc tr·∫£ l·ªùi:
    1. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p trong ph·∫ßn ng·ªØ c·∫£nh
    2. N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√™u r√µ v√† kh√¥ng ƒë∆∞a ra ph√°n ƒëo√°n
    3. Tr√≠ch d·∫´n c·ª• th·ªÉ c√°c ƒëi·ªÅu kho·∫£n li√™n quan ƒë·ªÉ h·ªó tr·ª£ c√¢u tr·∫£ l·ªùi
    4. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi ng√¥n ng·ªØ d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p khi c√≥ th·ªÉ
    5. Kh√¥ng t·∫°o ra th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, kh√¥ng ƒë∆∞a ra t∆∞ v·∫•n ph√°p l√Ω c√° nh√¢n
    6. Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Th√¥ng t∆∞ s·ªë m·∫•y, ƒêi·ªÅu m·∫•y) khi ƒë∆∞a ra th√¥ng tin
    7. ∆Øu ti√™n th√¥ng tin t·ª´ c√°c t√†i li·ªáu c√≥ ƒë·ªô tin c·∫≠y (relevance score) cao h∆°n khi c√≥ xung ƒë·ªôt ho·∫∑c m√¢u thu·∫´n
    8. Khi tr·∫£ l·ªùi, ∆∞u ti√™n th√¥ng tin t·ª´ t√†i li·ªáu c√≥ ƒëi·ªÉm s·ªë cao nh·∫•t tr∆∞·ªõc
    """
    
    full_prompt = f"{system_instructions}\n\nC√¢u h·ªèi: {query}\n\nNg·ªØ c·∫£nh t·ª´ c√°c t√†i li·ªáu ph√°p l√Ω (ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y):\n{documents}\n\nD·ª±a v√†o ng·ªØ c·∫£nh tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß."
    
    return full_prompt


def generate_response(query, documents):
    try:
        #format documents and create the prompt
        formatted_docs = format_documents(documents)
        full_prompt = create_prompt(query, formatted_docs)
        
        #initialize the model
        model = genai.GenerativeModel(MODEL_NAME)
        
        #generate the response
        try:
            response = model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=1024,
                    top_p=0.95,
                )
            )
            return response.text
        except Exception as config_error:
            print(f"Error with generation config, trying simpler call: {config_error}")
            response = model.generate_content(full_prompt)
            return response.text
        
    except Exception as e:
        print(f"Error generating response: {str(e)}")
        return f"ƒê√£ x·∫£y ra l·ªói khi t·∫°o ph·∫£n h·ªìi: {str(e)}"


def format_sources_for_display(documents, processing_time):
    sources_text = f"### Ngu·ªìn t√†i li·ªáu tham kh·∫£o (Th·ªùi gian x·ª≠ l√Ω: {processing_time:.2f}s)\n\n"
    
    for i, doc in enumerate(documents):
        metadata = doc.payload.get('metadata', {})
        thong_tu = metadata.get('Th√¥ng t∆∞', 'Unknown')
        dieu = metadata.get('ƒêi·ªÅu', 'Unknown')
        
        #extract a short preview of the document
        text = doc.payload.get('text', '')
        excerpt = text[:200] + "..." if len(text) > 200 else text
        
        #format the source information
        sources_text += f"**Ngu·ªìn #{i+1}:** Th√¥ng t∆∞ {thong_tu}, ƒêi·ªÅu {dieu} (ƒê·ªô tin c·∫≠y: {doc.score:.4f})\n\n"
        sources_text += f"*Tr√≠ch ƒëo·∫°n:* {excerpt}\n\n---\n\n"
    
    return sources_text


#process user query and return answer with its sources
def process_query(query, num_docs = 5):
    if not query.strip():
        return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n.", ""
    
    try:
        #track processing time
        start_time = time.time()
        
        #step 1, retrieve documents
        print(f"Retrieving documents for query: {query}")
        retrieved_docs = search_legal_documents(query, limit=num_docs)
        
        if not retrieved_docs:
            return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n.", ""
        
        #step 2, generate answer
        print(f"Generating response with {len(retrieved_docs)} documents")
        answer = generate_response(query, retrieved_docs)
        
        #step 3, format sources for display
        sources_text = format_sources_for_display(retrieved_docs, time.time() - start_time)
        
        return answer, sources_text
    
    except Exception as e:
        error_message = f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"
        print(error_message)
        return error_message, ""

#create and configure the gradio interface
def create_interface():
    with gr.Blocks(title="Tr·ª£ l√Ω Ph√°p l√Ω Vi·ªát Nam", theme=gr.themes.Soft()) as demo:
        #header
        gr.Markdown(
            f"""
            # üáªüá≥ Tr·ª£ l√Ω Ph√°p l√Ω
            
            H·ªá th·ªëng n√†y s·ª≠ d·ª•ng c√¥ng ngh·ªá RAG (Retrieval-Augmented Generation) ƒë·ªÉ tr·∫£ l·ªùi 
            c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn t√†i li·ªáu ph√°p l√Ω.
            
            *Model: {MODEL_NAME}*
            """
        )
        
        #input area
        with gr.Row():
            with gr.Column(scale=4):
                query_input = gr.Textbox(
                    label="C√¢u h·ªèi c·ªßa b·∫°n", 
                    placeholder="V√≠ d·ª•: ƒêi·ªÅu 4 trong th√¥ng t∆∞ 67 quy ƒë·ªãnh v·ªÅ g√¨?",
                    lines=2
                )
            
            with gr.Column(scale=1):
                num_docs = gr.Slider(
                    minimum=1, 
                    maximum=10, 
                    value=5, 
                    step=1, 
                    label="S·ªë l∆∞·ª£ng t√†i li·ªáu"
                )
        
        #submit button
        submit_btn = gr.Button("G·ª≠i", variant="primary")
        
        #output area
        with gr.Row():
            with gr.Column(scale=3):
                answer_output = gr.Markdown(label="C√¢u tr·∫£ l·ªùi")
            with gr.Column(scale=2):
                sources_output = gr.Markdown(label="Ngu·ªìn t√†i li·ªáu")
        
        #event handlers
        submit_btn.click(
            fn=process_query, 
            inputs=[query_input, num_docs], 
            outputs=[answer_output, sources_output]
        )
        query_input.submit(
            fn=process_query, 
            inputs=[query_input, num_docs], 
            outputs=[answer_output, sources_output]
        )
        
        #example questions
        gr.Examples(
            examples=[
                ["Ph√≠ b·∫£o hi·ªÉm xe c∆° gi·ªõi l√† g√¨?"],
                ["ƒêi·ªÅu 4 trong th√¥ng t∆∞ 67 quy ƒë·ªãnh v·ªÅ g√¨?"],
                ["ƒêi·ªÅu 2 v√† ƒêi·ªÅu 3 trong th√¥ng t∆∞ 67 bao g·ªìm nh·ªØng g√¨?"]
            ],
            inputs=query_input
        )
        
    return demo


if __name__ == "__main__":
    demo = create_interface()
    demo.launch(share=True)  #set share=True to create a public link